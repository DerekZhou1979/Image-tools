#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Image-tools é€šç”¨å›¾ç‰‡ä¸‹è½½å™¨
è‡ªåŠ¨ä»æŒ‡å®šç½‘ç«™ä¸‹è½½å›¾ç‰‡å¹¶ä¿å­˜åˆ°æŒ‡å®šç›®å½•ï¼Œæ”¯æŒæ™ºèƒ½é‡å‘½å
"""

import os
import sys
import json
import requests
from urllib.parse import urljoin, urlparse
from pathlib import Path
import time
from bs4 import BeautifulSoup
import re
from urllib.request import urlopen
from urllib.error import HTTPError, URLError

# Gemini Vision API ç›¸å…³å¯¼å…¥
try:
    import google.generativeai as genai
    from PIL import Image
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    print("âš ï¸  Gemini Vision API ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨åŸºç¡€åŒ¹é…æ¨¡å¼")

class ImageDownloader:
    def __init__(self, config_file='image_download_config.json'):
        """åˆå§‹åŒ–ä¸‹è½½å™¨"""
        self.config_file = config_file
        self.load_config()
        self.base_url = self.config.get('base_url', 'https://example.com/')
        self.images_dir = Path('./images')
        self.session = requests.Session()
        
        # æ¨¡å¼æ§åˆ¶æ ‡å¿—
        self.force_matching_mode = False
        self.force_download_all = False
        self.use_gemini_vision = False
        
        # è®¾ç½®è¯·æ±‚å¤´ï¼Œæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨è®¿é—®
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
            'Cache-Control': 'max-age=0',
        })
        
        # æ”¯æŒcookieå’Œä¼šè¯ç®¡ç†
        self.session.cookies.update({
            'lang': 'zh-CN',
            'timezone': 'Asia/Shanghai'
        })
        
        # åˆ›å»ºimagesç›®å½•
        self.images_dir.mkdir(exist_ok=True)
        
        # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°ï¼Œå†³å®šæ˜¯å¦éœ€è¦åˆå§‹åŒ– Gemini API
        self.need_gemini = len(sys.argv) > 1 and sys.argv[1] == '--gemini'
        
        # åˆå§‹åŒ– Gemini APIï¼ˆä»…åœ¨éœ€è¦æ—¶ï¼‰
        if self.need_gemini:
            self.init_gemini_api()
        else:
            self.gemini_model = None
            self.use_gemini_vision = False
    
    def init_gemini_api(self):
        """åˆå§‹åŒ– Gemini API"""
        if not GEMINI_AVAILABLE:
            self.gemini_model = None
            return
        
        # è·å–å½“å‰locationä¿¡æ¯
        print("ğŸŒ æ£€æµ‹å½“å‰åœ°ç†ä½ç½®å’Œç½‘ç»œç¯å¢ƒ...")
        self._detect_location()
        
        # åªä»ç¯å¢ƒå˜é‡è·å– API å¯†é’¥
        api_key = os.getenv('GEMINI_API_KEY')
        if not api_key:
            print("âŒ æœªæ‰¾åˆ° GEMINI_API_KEY ç¯å¢ƒå˜é‡")
            print("\nğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
            print("   è¯·åœ¨è¿è¡Œå‰è®¾ç½®ç¯å¢ƒå˜é‡:")
            print("   export GEMINI_API_KEY='your_api_key_here'")
            print("   ")
            print("   è·å–APIå¯†é’¥: https://makersuite.google.com/app/apikey")
            print("   è¯¦ç»†é…ç½®è¯·æŸ¥çœ‹: GEMINI_SETUP.md")
            print(f"\nğŸ›‘ ç¨‹åºå°†é€€å‡ºï¼Œè¯·è®¾ç½®APIå¯†é’¥åé‡æ–°è¿è¡Œ")
            sys.exit(1)

        try:
            print("ğŸ” é…ç½®Gemini APIå¯†é’¥...")
            genai.configure(api_key=api_key)
            # ä½¿ç”¨æœ€æ–°çš„ Gemini 2.5 Flash Preview æ¨¡å‹
            self.gemini_model = genai.GenerativeModel('gemini-2.5-flash-preview-05-20')
            
            # æµ‹è¯•APIè¿æ¥
            print("ğŸ§ª æµ‹è¯•Gemini APIè¿æ¥...")
            test_response = self.gemini_model.generate_content("Hello")
            if test_response.text:
                self.use_gemini_vision = True
                print("âœ… Gemini Vision API å·²é…ç½®æˆåŠŸå¹¶é€šè¿‡è¿æ¥æµ‹è¯•")
            else:
                raise Exception("APIæµ‹è¯•æ— å“åº”")
                
        except Exception as e:
            error_msg = str(e)
            print(f"âŒ Gemini API é…ç½®å¤±è´¥: {error_msg}")
            
            # åˆ†æå…·ä½“é”™è¯¯ç±»å‹å¹¶æä¾›è§£å†³æ–¹æ¡ˆ
            if "User location is not supported" in error_msg:
                print("\nğŸš« åœ°ç†ä½ç½®é™åˆ¶é”™è¯¯è¯¦æƒ…:")
                print("   - é”™è¯¯ç±»å‹: Gemini API åœ°ç†ä½ç½®ä¸æ”¯æŒ")
                print("   - å¯èƒ½åŸå› : å½“å‰åœ°åŒºä¸åœ¨ Google Gemini API æ”¯æŒèŒƒå›´å†…")
                print("\nğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
                print("   1. ä½¿ç”¨VPNè¿æ¥åˆ°æ”¯æŒçš„åœ°åŒº (å¦‚ç¾å›½ã€è‹±å›½ç­‰)")
                print("   2. ç¡®ä¿VPNå…¨å±€ä»£ç†æ¨¡å¼ï¼Œè€Œéåˆ†æµæ¨¡å¼")
                print("   3. æ£€æŸ¥IPåœ°å€æ˜¯å¦ä¸ºæ”¯æŒåœ°åŒºçš„IP")
                print("   4. æˆ–è€…ä½¿ç”¨ --rename æ¨¡å¼è¿›è¡ŒåŸºç¡€æ™ºèƒ½é‡å‘½å")
                
            elif "invalid" in error_msg.lower() or "key" in error_msg.lower():
                print("\nğŸ”‘ APIå¯†é’¥é”™è¯¯è¯¦æƒ…:")
                print("   - é”™è¯¯ç±»å‹: APIå¯†é’¥æ— æ•ˆæˆ–å·²è¿‡æœŸ")
                print("\nğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
                print("   1. æ£€æŸ¥GEMINI_API_KEYæ˜¯å¦æ­£ç¡®")
                print("   2. å‰å¾€ https://makersuite.google.com/app/apikey ç”Ÿæˆæ–°å¯†é’¥")
                print("   3. ç¡®ä¿APIå¯†é’¥å…·æœ‰Gemini Visionæƒé™")
                
            elif "quota" in error_msg.lower() or "limit" in error_msg.lower():
                print("\nğŸ“Š é…é¢é™åˆ¶é”™è¯¯è¯¦æƒ…:")
                print("   - é”™è¯¯ç±»å‹: APIé…é¢ä¸è¶³æˆ–è¯·æ±‚é¢‘ç‡è¿‡é«˜")
                print("\nğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
                print("   1. ç­‰å¾…é…é¢é‡ç½® (é€šå¸¸ä¸ºæ¯æ—¥é‡ç½®)")
                print("   2. å‡çº§APIè®¡åˆ’è·å¾—æ›´é«˜é…é¢")
                print("   3. é™ä½è¯·æ±‚é¢‘ç‡")
                
            else:
                print(f"\nğŸ”§ ç½‘ç»œè¿æ¥é”™è¯¯è¯¦æƒ…:")
                print(f"   - é”™è¯¯ç±»å‹: {error_msg}")
                print("\nğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
                print("   1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
                print("   2. ç¡®è®¤é˜²ç«å¢™è®¾ç½®")
                print("   3. å°è¯•ä½¿ç”¨VPN")
            
            print(f"\nğŸ›‘ ç”±äºGemini APIä¸å¯ç”¨ï¼Œç¨‹åºå°†é€€å‡º")
            print(f"ğŸ’¡ å»ºè®®: ä½¿ç”¨ './start_download.sh rename' è¿›è¡ŒåŸºç¡€æ™ºèƒ½é‡å‘½å")
            
            # ç›´æ¥é€€å‡ºç¨‹åº
            sys.exit(1)
    
    def _detect_location(self):
        """æ£€æµ‹å½“å‰åœ°ç†ä½ç½®ï¼Œä½¿ç”¨å¤šä¸ªå¤‡ç”¨APIæœåŠ¡"""
        location_apis = [
            {
                'name': 'IPApi.co',
                'url': 'https://ipapi.co/json/',
                'timeout': 8
            },
            {
                'name': 'IP-API.com', 
                'url': 'http://ip-api.com/json/',
                'timeout': 6
            },
            {
                'name': 'IPInfo.io',
                'url': 'https://ipinfo.io/json',
                'timeout': 8
            },
            {
                'name': 'HTTPBin.org',
                'url': 'https://httpbin.org/ip',
                'timeout': 5
            }
        ]
        
        for api in location_apis:
            try:
                import requests
                print(f"ğŸ” å°è¯•é€šè¿‡ {api['name']} è·å–åœ°ç†ä½ç½®...")
                
                response = requests.get(api['url'], timeout=api['timeout'])
                if response.status_code == 200:
                    location_data = response.json()
                    
                    if api['name'] == 'IPApi.co':
                        print(f"ğŸ“ å½“å‰å…¬ç½‘IP: {location_data.get('ip', 'æœªçŸ¥')}")
                        print(f"ğŸ—ºï¸  åœ°ç†ä½ç½®: {location_data.get('country_name', 'æœªçŸ¥')} - {location_data.get('city', 'æœªçŸ¥')}")
                        print(f"ğŸ¢ ISP: {location_data.get('org', 'æœªçŸ¥')}")
                        return
                    elif api['name'] == 'IP-API.com':
                        print(f"ğŸ“ å½“å‰å…¬ç½‘IP: {location_data.get('query', 'æœªçŸ¥')}")
                        print(f"ğŸ—ºï¸  åœ°ç†ä½ç½®: {location_data.get('country', 'æœªçŸ¥')} - {location_data.get('city', 'æœªçŸ¥')}")
                        print(f"ğŸ¢ ISP: {location_data.get('isp', 'æœªçŸ¥')}")
                        return
                    elif api['name'] == 'IPInfo.io':
                        print(f"ğŸ“ å½“å‰å…¬ç½‘IP: {location_data.get('ip', 'æœªçŸ¥')}")
                        print(f"ğŸ—ºï¸  åœ°ç†ä½ç½®: {location_data.get('country', 'æœªçŸ¥')} - {location_data.get('city', 'æœªçŸ¥')}")
                        print(f"ğŸ¢ ISP: {location_data.get('org', 'æœªçŸ¥')}")
                        return
                    elif api['name'] == 'HTTPBin.org':
                        print(f"ğŸ“ å½“å‰å…¬ç½‘IP: {location_data.get('origin', 'æœªçŸ¥')}")
                        print(f"ğŸ—ºï¸  åœ°ç†ä½ç½®: æ­£åœ¨è§£æ...")
                        return
                        
            except requests.exceptions.Timeout:
                print(f"â° {api['name']} å“åº”è¶…æ—¶ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæœåŠ¡...")
                continue
            except requests.exceptions.ConnectionError:
                print(f"ğŸ”Œ {api['name']} è¿æ¥å¤±è´¥ï¼Œå°è¯•ä¸‹ä¸€ä¸ªæœåŠ¡...")
                continue
            except Exception as e:
                print(f"âš ï¸  {api['name']} è·å–å¤±è´¥: {e}")
                continue
        
        # æ‰€æœ‰APIéƒ½å¤±è´¥çš„æƒ…å†µ
        print("âš ï¸  æ‰€æœ‰åœ°ç†ä½ç½®æœåŠ¡éƒ½æ— æ³•è®¿é—®")
        print("ğŸ’¡ è¿™å¯èƒ½ä¸ä¼šå½±å“Gemini APIçš„æ­£å¸¸ä½¿ç”¨")
        print("ğŸŒ å¦‚æœGemini APIæŠ¥é”™åœ°ç†ä½ç½®é™åˆ¶ï¼Œè¯·è€ƒè™‘ä½¿ç”¨VPN")
    
    def load_config(self):
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        try:
            with open(self.config_file, 'r', encoding='utf-8') as f:
                self.config = json.load(f)
            print(f"âœ… å·²åŠ è½½é…ç½®æ–‡ä»¶: {self.config_file}")
        except FileNotFoundError:
            print(f"âŒ é…ç½®æ–‡ä»¶ {self.config_file} ä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»ºé…ç½®æ–‡ä»¶")
            sys.exit(1)
        except json.JSONDecodeError:
            print(f"âŒ é…ç½®æ–‡ä»¶ {self.config_file} æ ¼å¼é”™è¯¯")
            sys.exit(1)
    
    def get_page_content(self, url):
        """è·å–ç½‘é¡µå†…å®¹ï¼Œå¸¦å¼ºåŒ–çš„é‡è¯•æœºåˆ¶å’Œåçˆ¬è™«å¯¹ç­–"""
        max_retries = 5
        timeout_values = [30, 45, 60, 75, 90]  # é€’å¢çš„è¶…æ—¶æ—¶é—´
        
        for attempt in range(max_retries):
            try:
                timeout = timeout_values[attempt]
                print(f"ğŸŒ æ­£åœ¨è®¿é—®: {url} (å°è¯• {attempt + 1}/{max_retries}, è¶…æ—¶è®¾ç½®: {timeout}ç§’)")
                
                # åŠ¨æ€è°ƒæ•´è¯·æ±‚å¤´ï¼Œæ¨¡æ‹Ÿä¸åŒçš„æµè§ˆå™¨è¡Œä¸º
                self._randomize_headers()
                
                # æ·»åŠ éšæœºå»¶è¿Ÿï¼Œæ¨¡æ‹Ÿäººç±»è®¿é—®è¡Œä¸º
                if attempt > 0:
                    delay = 2 + attempt * 3  # 2, 5, 8, 11, 14ç§’
                    print(f"â±ï¸  äººç±»åŒ–å»¶è¿Ÿ {delay} ç§’...")
                    time.sleep(delay)
                
                response = self.session.get(url, timeout=timeout, allow_redirects=True)
                
                # æ£€æŸ¥å“åº”çŠ¶æ€
                if response.status_code == 403:
                    print(f"ğŸš« æ£€æµ‹åˆ°403 Forbiddené”™è¯¯ - ç½‘ç«™å¯ç”¨äº†é˜²çˆ¬è™«æœºåˆ¶")
                    if attempt < max_retries - 1:
                        print(f"ğŸ”„ å°è¯•ä½¿ç”¨å¤‡ç”¨ç­–ç•¥...")
                        self._handle_403_error(url, attempt)
                        continue
                    else:
                        print(f"âŒ æ— æ³•ç»•è¿‡é˜²çˆ¬è™«æœºåˆ¶ï¼Œå»ºè®®ï¼š")
                        print(f"   1. æ£€æŸ¥ç½‘ç«™çš„robots.txtæ–‡ä»¶")
                        print(f"   2. ç¡®è®¤æ˜¯å¦éœ€è¦ç™»å½•æˆ–éªŒè¯")
                        print(f"   3. ä½¿ç”¨ä»£ç†æˆ–VPNæ›´æ¢IPåœ°å€")
                        print(f"   4. è”ç³»ç½‘ç«™ç®¡ç†å‘˜è·å–APIè®¿é—®æƒé™")
                        return None
                elif response.status_code == 429:
                    print(f"ğŸŒ æ£€æµ‹åˆ°429 Too Many Requests - è®¿é—®é¢‘ç‡è¿‡é«˜")
                    if attempt < max_retries - 1:
                        wait_time = 30 * (attempt + 1)  # 30, 60, 90, 120ç§’
                        print(f"â±ï¸  ç­‰å¾… {wait_time} ç§’ä»¥é™ä½è®¿é—®é¢‘ç‡...")
                        time.sleep(wait_time)
                        continue
                
                response.raise_for_status()
                print(f"âœ… ç½‘é¡µè®¿é—®æˆåŠŸ (çŠ¶æ€ç : {response.status_code})")
                return response.text
                
            except requests.exceptions.Timeout:
                print(f"â° ç¬¬ {attempt + 1} æ¬¡å°è¯•è¶…æ—¶")
            except requests.exceptions.ConnectionError as e:
                print(f"ğŸ”Œ ç¬¬ {attempt + 1} æ¬¡è¿æ¥å¤±è´¥: {e}")
            except requests.exceptions.HTTPError as e:
                print(f"ğŸš« ç¬¬ {attempt + 1} æ¬¡HTTPé”™è¯¯: {e}")
                if "403" in str(e):
                    print(f"ğŸ’¡ å»ºè®®: è¿™å¯èƒ½æ˜¯ç½‘ç«™çš„åçˆ¬è™«æœºåˆ¶ï¼Œå°è¯•ï¼š")
                    print(f"   - é™ä½è®¿é—®é¢‘ç‡")
                    print(f"   - ä½¿ç”¨ä¸åŒçš„User-Agent")
                    print(f"   - æ£€æŸ¥æ˜¯å¦éœ€è¦ç‰¹æ®Šçš„è®¤è¯å¤´")
            except requests.RequestException as e:
                print(f"âš ï¸  ç¬¬ {attempt + 1} æ¬¡è¯·æ±‚å¤±è´¥: {e}")
            
            if attempt < max_retries - 1:
                wait_time = 5 * (attempt + 1)  # 5, 10, 15, 20ç§’
                print(f"â±ï¸  ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                time.sleep(wait_time)
        
        print(f"âŒ è®¿é—®ç½‘é¡µå¤±è´¥ï¼Œå·²å°è¯• {max_retries} æ¬¡")
        return None
    
    def _randomize_headers(self):
        """éšæœºåŒ–è¯·æ±‚å¤´ï¼Œæ¨¡æ‹Ÿä¸åŒçš„æµè§ˆå™¨ç¯å¢ƒ"""
        import random
        
        user_agents = [
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2.1 Safari/605.1.15',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:122.0) Gecko/20100101 Firefox/122.0',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:122.0) Gecko/20100101 Firefox/122.0'
        ]
        
        # éšæœºé€‰æ‹©User-Agent
        self.session.headers['User-Agent'] = random.choice(user_agents)
        
        # éšæœºåŒ–å…¶ä»–å¤´éƒ¨
        accept_languages = [
            'zh-CN,zh;q=0.9,en;q=0.8',
            'en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7',
            'zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2'
        ]
        self.session.headers['Accept-Language'] = random.choice(accept_languages)
    
    def _handle_403_error(self, url, attempt):
        """å¤„ç†403é”™è¯¯çš„ç‰¹æ®Šç­–ç•¥"""
        print(f"ğŸ›¡ï¸  å°è¯•åçˆ¬è™«ç­–ç•¥ {attempt + 1}:")
        
        # ç­–ç•¥1: æ¸…é™¤å¯èƒ½çš„è·Ÿè¸ªæ ‡è¯†
        if attempt == 0:
            print("   - æ¸…é™¤DNTå’ŒSec-Fetchå¤´éƒ¨")
            headers_to_remove = ['DNT', 'Sec-Fetch-Dest', 'Sec-Fetch-Mode', 'Sec-Fetch-Site', 'Sec-Fetch-User']
            for header in headers_to_remove:
                self.session.headers.pop(header, None)
        
        # ç­–ç•¥2: æ¨¡æ‹Ÿç§»åŠ¨è®¾å¤‡
        elif attempt == 1:
            print("   - åˆ‡æ¢åˆ°ç§»åŠ¨è®¾å¤‡User-Agent")
            self.session.headers['User-Agent'] = 'Mozilla/5.0 (iPhone; CPU iPhone OS 17_2_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.2 Mobile/15E148 Safari/604.1'
        
        # ç­–ç•¥3: æ·»åŠ Referer
        elif attempt == 2:
            print("   - æ·»åŠ Refererå¤´éƒ¨")
            from urllib.parse import urljoin, urlparse
            parsed = urlparse(url)
            base_url = f"{parsed.scheme}://{parsed.netloc}"
            self.session.headers['Referer'] = base_url
        
        # ç­–ç•¥4: æ¨¡æ‹Ÿæ—§ç‰ˆæµè§ˆå™¨
        elif attempt == 3:
            print("   - ä½¿ç”¨æ—§ç‰ˆæµè§ˆå™¨æ ‡è¯†")
            self.session.headers['User-Agent'] = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    
    def find_images_on_page(self, html_content, base_url):
        """åœ¨ç½‘é¡µä¸­æŸ¥æ‰¾å›¾ç‰‡URL"""
        soup = BeautifulSoup(html_content, 'html.parser')
        image_urls = []
        
        # æŸ¥æ‰¾æ‰€æœ‰imgæ ‡ç­¾
        for img in soup.find_all('img'):
            src = img.get('src') or img.get('data-src') or img.get('data-lazy-src')
            if src:
                # è½¬æ¢ä¸ºç»å¯¹URL
                full_url = urljoin(base_url, src)
                if self.is_valid_image_url(full_url):
                    image_urls.append(full_url)
        
        # æŸ¥æ‰¾èƒŒæ™¯å›¾ç‰‡
        for element in soup.find_all(attrs={'style': re.compile(r'background.*?url')}):
            style = element.get('style', '')
            urls = re.findall(r'url\(["\']?(.*?)["\']?\)', style)
            for url in urls:
                full_url = urljoin(base_url, url)
                if self.is_valid_image_url(full_url):
                    image_urls.append(full_url)
        
        return list(set(image_urls))  # å»é‡
    
    def is_valid_image_url(self, url):
        """æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„å›¾ç‰‡URL"""
        image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.webp', '.bmp']
        parsed_url = urlparse(url)
        path = parsed_url.path.lower()
        
        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        for ext in image_extensions:
            if path.endswith(ext):
                return True
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¸¸è§çš„å›¾ç‰‡å…³é”®è¯
        image_keywords = ['img', 'image', 'photo', 'pic', 'thumb', 'banner']
        for keyword in image_keywords:
            if keyword in path:
                return True
        
        return False
    
    def download_image(self, url, filename):
        """ä¸‹è½½å•å¼ å›¾ç‰‡ï¼Œå¸¦é‡è¯•å’ŒéªŒè¯æœºåˆ¶"""
        max_retries = 3
        
        for attempt in range(max_retries):
            try:
                print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½: {filename}" + (f" (é‡è¯• {attempt + 1})" if attempt > 0 else ""))
                
                # ä¸ºå›¾ç‰‡ä¸‹è½½è®¾ç½®ä¸“é—¨çš„è¯·æ±‚å¤´
                image_headers = {
                    'Accept': 'image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8',
                    'Sec-Fetch-Dest': 'image',
                    'Sec-Fetch-Mode': 'no-cors',
                    'Sec-Fetch-Site': 'same-origin',
                }
                
                # å¦‚æœæ˜¯é‡è¯•ï¼Œæ·»åŠ å»¶è¿Ÿ
                if attempt > 0:
                    delay = 2 ** attempt  # 2, 4ç§’
                    print(f"   â±ï¸  ç­‰å¾… {delay} ç§’åé‡è¯•...")
                    time.sleep(delay)
                
                response = self.session.get(url, timeout=45, stream=True, headers=image_headers)
                
                # æ£€æŸ¥å“åº”çŠ¶æ€
                if response.status_code == 403:
                    print(f"   ğŸš« å›¾ç‰‡è®¿é—®è¢«æ‹’ç» (403)")
                    if attempt < max_retries - 1:
                        # å°è¯•ä¸å¸¦é¢å¤–å¤´éƒ¨ä¸‹è½½
                        print(f"   ğŸ”„ å°è¯•ç®€åŒ–è¯·æ±‚å¤´...")
                        continue
                    else:
                        print(f"   âŒ æ— æ³•ä¸‹è½½æ­¤å›¾ç‰‡ï¼Œå¯èƒ½å—åˆ°è®¿é—®é™åˆ¶")
                        return False
                
                response.raise_for_status()
                
                # éªŒè¯å†…å®¹ç±»å‹
                content_type = response.headers.get('content-type', '').lower()
                if not any(img_type in content_type for img_type in ['image/', 'application/octet-stream']):
                    print(f"   âš ï¸  è­¦å‘Š: å“åº”å†…å®¹ç±»å‹å¯èƒ½ä¸æ˜¯å›¾ç‰‡ ({content_type})")
                
                file_path = self.images_dir / filename
                
                # ä¸‹è½½æ–‡ä»¶
                with open(file_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                
                # éªŒè¯ä¸‹è½½çš„æ–‡ä»¶
                file_size = file_path.stat().st_size
                if file_size == 0:
                    print(f"   âŒ ä¸‹è½½çš„æ–‡ä»¶ä¸ºç©º")
                    file_path.unlink(missing_ok=True)  # åˆ é™¤ç©ºæ–‡ä»¶
                    if attempt < max_retries - 1:
                        continue
                    return False
                elif file_size < 100:  # å°äº100å­—èŠ‚å¯èƒ½æ˜¯é”™è¯¯é¡µé¢
                    print(f"   âš ï¸  ä¸‹è½½çš„æ–‡ä»¶å¾ˆå° ({file_size} bytes)ï¼Œå¯èƒ½æ˜¯é”™è¯¯å“åº”")
                    # æ£€æŸ¥æ–‡ä»¶å†…å®¹
                    with open(file_path, 'r', errors='ignore') as f:
                        content = f.read()
                        if any(error_text in content.lower() for error_text in ['error', '404', '403', 'forbidden', 'not found']):
                            print(f"   âŒ æ–‡ä»¶å†…å®¹åŒ…å«é”™è¯¯ä¿¡æ¯")
                            file_path.unlink(missing_ok=True)
                            if attempt < max_retries - 1:
                                continue
                            return False
                
                print(f"âœ… ä¸‹è½½å®Œæˆ: {filename} ({self.format_file_size(file_size)})")
                return True
                
            except requests.exceptions.Timeout:
                print(f"   â° ä¸‹è½½è¶…æ—¶")
            except requests.exceptions.ConnectionError as e:
                print(f"   ğŸ”Œ è¿æ¥å¤±è´¥: {e}")
            except requests.exceptions.HTTPError as e:
                print(f"   ğŸš« HTTPé”™è¯¯: {e}")
                if "403" in str(e) or "Forbidden" in str(e):
                    print(f"   ğŸ’¡ å»ºè®®: æ­¤å›¾ç‰‡å¯èƒ½å—åˆ°è®¿é—®é™åˆ¶")
            except Exception as e:
                print(f"   âŒ ä¸‹è½½å¼‚å¸¸: {e}")
        
        print(f"âŒ ä¸‹è½½å¤±è´¥: {filename} - å·²å°è¯• {max_retries} æ¬¡")
        return False
    
    def format_file_size(self, size_bytes):
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°æ˜¾ç¤º"""
        if size_bytes == 0:
            return "0 B"
        size_names = ["B", "KB", "MB", "GB"]
        import math
        i = int(math.floor(math.log(size_bytes, 1024)))
        p = math.pow(1024, i)
        s = round(size_bytes / p, 1)
        return f"{s} {size_names[i]}"
    
    def search_and_download_images(self):
        """æœç´¢å¹¶ä¸‹è½½é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šçš„å›¾ç‰‡"""
        site_name = self.config.get('site_name', 'ç›®æ ‡ç½‘ç«™')
        print(f"ğŸš€ å¼€å§‹ä¸‹è½½ {site_name} å›¾ç‰‡...")
        print("=" * 60)
        
        total_downloaded = 0
        total_failed = 0
        
        # è·å–æ‰€æœ‰å›¾ç‰‡URL
        all_image_urls = self.get_all_image_urls()
        
        if not all_image_urls:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•å›¾ç‰‡")
            return
        
        print(f"ğŸ” æ€»å…±æ‰¾åˆ° {len(all_image_urls)} å¼ ä¸é‡å¤çš„å›¾ç‰‡")
        print("=" * 60)
        
        # æ ¹æ®è®¾ç½®çš„æ¨¡å¼æ ‡å¿—é€‰æ‹©ä¸‹è½½æ–¹å¼
        if self.force_matching_mode:
            print("\nğŸ¯ ä½¿ç”¨æ™ºèƒ½åŒ¹é…æ¨¡å¼")
            total_downloaded, total_failed = self.download_with_matching()
        elif self.force_download_all:
            print("\nğŸ“¥ ä½¿ç”¨å…¨é‡ä¸‹è½½æ¨¡å¼")
            total_downloaded, total_failed = self.download_all_images(all_image_urls)
        else:
            # äº¤äº’æ¨¡å¼ï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ä½œä¸ºå¤‡ç”¨ï¼‰
            print("\nğŸ¤– è¯·é€‰æ‹©ä¸‹è½½æ¨¡å¼:")
            print("1. æ™ºèƒ½åŒ¹é…æ¨¡å¼ (æ ¹æ®é…ç½®æ–‡ä»¶åŒ¹é…ç‰¹å®šå›¾ç‰‡)")
            print("2. å…¨é‡ä¸‹è½½æ¨¡å¼ (ä¸‹è½½æ‰€æœ‰æ‰¾åˆ°çš„å›¾ç‰‡)")
            
            try:
                choice = input("è¯·è¾“å…¥é€‰æ‹© (1 æˆ– 2ï¼Œé»˜è®¤ä¸º 2): ").strip()
                if not choice:
                    choice = "2"
            except:
                choice = "2"
            
            if choice == "1":
                total_downloaded, total_failed = self.download_with_matching()
            else:
                total_downloaded, total_failed = self.download_all_images(all_image_urls)
        
        print("\n" + "=" * 60)
        print(f"ğŸ“Š ä¸‹è½½ç»Ÿè®¡:")
        print(f"âœ… æˆåŠŸä¸‹è½½: {total_downloaded} å¼ ")
        print(f"âŒ ä¸‹è½½å¤±è´¥: {total_failed} å¼ ")
        print("ğŸ‰ ä¸‹è½½ä»»åŠ¡å®Œæˆ!")
        
        # å¦‚æœæœ‰æˆåŠŸä¸‹è½½çš„å›¾ç‰‡ï¼Œæ‰§è¡Œæ™ºèƒ½é‡å‘½åï¼ˆé™¤éæ˜¯Geminiæ¨¡å¼ï¼‰
        if total_downloaded > 0 and not self.use_gemini_vision:
            self.smart_rename_images()
    
    def get_all_image_urls(self):
        """è·å–æ‰€æœ‰å›¾ç‰‡URL"""
        # é¦–å…ˆè®¿é—®ä¸»é¡µï¼Œè·å–æ‰€æœ‰å¯èƒ½çš„å›¾ç‰‡URL
        main_page_content = self.get_page_content(self.base_url)
        if not main_page_content:
            print("âŒ æ— æ³•è®¿é—®ä¸»é¡µï¼Œé€€å‡ºç¨‹åº")
            return []
        
        # è·å–ä¸»é¡µæ‰€æœ‰å›¾ç‰‡URL
        all_image_urls = self.find_images_on_page(main_page_content, self.base_url)
        print(f"ğŸ” åœ¨ä¸»é¡µæ‰¾åˆ° {len(all_image_urls)} å¼ å›¾ç‰‡")
        
        # å·²çŸ¥æœ‰æ•ˆçš„é¡µé¢åˆ—è¡¨ï¼ˆå·²éªŒè¯å¯è®¿é—®ï¼‰
        working_pages = [
            'news/', 'master/'
        ]
        
        # è®¿é—®å·²çŸ¥æœ‰æ•ˆçš„é¡µé¢
        for page in working_pages:
            page_url = urljoin(self.base_url, page)
            page_content = self.get_page_content(page_url)
            if page_content:
                page_images = self.find_images_on_page(page_content, page_url)
                all_image_urls.extend(page_images)
                print(f"ğŸ” åœ¨ {page} æ‰¾åˆ° {len(page_images)} å¼ å›¾ç‰‡")
            time.sleep(0.5)  # å‡å°‘ç­‰å¾…æ—¶é—´ï¼Œæé«˜æ•ˆç‡
        
        # å»é‡æ‰€æœ‰å›¾ç‰‡URL
        return list(set(all_image_urls))
    
    def download_with_matching(self):
        """ä½¿ç”¨é…ç½®æ–‡ä»¶åŒ¹é…ä¸‹è½½"""
        all_image_urls = self.get_all_image_urls()
        total_downloaded = 0
        total_failed = 0
        
        # æ ¹æ®é…ç½®æ–‡ä»¶ä¸‹è½½æŒ‡å®šå›¾ç‰‡
        for category, images in self.config['image_categories'].items():
            print(f"\nğŸ“ æ­£åœ¨å¤„ç†åˆ†ç±»: {category}")
            print("-" * 40)
            
            for image_info in images:
                filename = image_info['filename']
                keywords = image_info['keywords']
                description = image_info['description']
                
                print(f"ğŸ¯ å¯»æ‰¾åŒ¹é…å›¾ç‰‡: {description}")
                
                # æ ¹æ®å…³é”®è¯åŒ¹é…æœ€åˆé€‚çš„å›¾ç‰‡
                best_match = self.find_best_matching_image(all_image_urls, keywords)
                
                if best_match:
                    if self.download_image(best_match, filename):
                        total_downloaded += 1
                    else:
                        total_failed += 1
                else:
                    print(f"âš ï¸  æœªæ‰¾åˆ°åŒ¹é…çš„å›¾ç‰‡: {filename}")
                    total_failed += 1
                
                time.sleep(0.5)  # é¿å…ä¸‹è½½è¿‡å¿«
        
        return total_downloaded, total_failed
    
    def download_all_images(self, image_urls):
        """ä¸‹è½½æ‰€æœ‰æ‰¾åˆ°çš„å›¾ç‰‡"""
        total_downloaded = 0
        total_failed = 0
        
        print(f"\nğŸ“¥ å¼€å§‹ä¸‹è½½æ‰€æœ‰å›¾ç‰‡ (å…± {len(image_urls)} å¼ )")
        print("-" * 60)
        
        for i, url in enumerate(image_urls, 1):
            # ç”Ÿæˆæ–‡ä»¶å
            filename = self.generate_filename(url, i)
            
            print(f"ğŸ“¥ [{i}/{len(image_urls)}] æ­£åœ¨ä¸‹è½½: {filename}")
            
            if self.download_image(url, filename):
                total_downloaded += 1
            else:
                total_failed += 1
            
            time.sleep(0.3)  # é¿å…ä¸‹è½½è¿‡å¿«
        
        return total_downloaded, total_failed
    
    def generate_filename(self, url, index):
        """æ ¹æ®URLç”Ÿæˆåˆé€‚çš„æ–‡ä»¶å"""
        parsed_url = urlparse(url)
        original_filename = os.path.basename(parsed_url.path)
        
        if original_filename and '.' in original_filename:
            # æœ‰åŸå§‹æ–‡ä»¶å
            name, ext = os.path.splitext(original_filename)
            return f"image_{index:03d}_{name}{ext}"
        else:
            # æ²¡æœ‰åŸå§‹æ–‡ä»¶åï¼Œæ ¹æ®URLç‰¹å¾ç”Ÿæˆ
            url_parts = [part for part in parsed_url.path.split('/') if part]
            if url_parts:
                name_part = '_'.join(url_parts[-2:])  # å–æœ€åä¸¤ä¸ªè·¯å¾„éƒ¨åˆ†
                return f"image_{index:03d}_{name_part}.jpg"
            else:
                return f"image_{index:03d}.jpg"
    
    def find_best_matching_image(self, image_urls, keywords):
        """æ ¹æ®å…³é”®è¯æ‰¾åˆ°æœ€åŒ¹é…çš„å›¾ç‰‡URL - ä¼˜åŒ–ç‰ˆæœ¬"""
        scored_images = []
        
        for url in image_urls:
            score = 0
            url_lower = url.lower()
            
            # è®¡ç®—åŒ¹é…åˆ†æ•° - æ›´å®½æ¾çš„åŒ¹é…ç­–ç•¥
            for keyword in keywords:
                keyword_lower = keyword.lower()
                
                # URLä¸­åŒ…å«å…³é”®è¯
                if keyword_lower in url_lower:
                    score += 5
                    
                # æ–‡ä»¶ååŒ¹é…æƒé‡æ›´é«˜
                filename = os.path.basename(urlparse(url).path).lower()
                if keyword_lower in filename:
                    score += 15
                
                # è·¯å¾„åŒ¹é…
                path = urlparse(url).path.lower()
                if keyword_lower in path:
                    score += 8
            
            # å³ä½¿æ²¡æœ‰å…³é”®è¯åŒ¹é…ï¼Œä¹Ÿç»™ä¸€ä¸ªåŸºç¡€åˆ†æ•°ï¼Œç¡®ä¿æœ‰å›¾ç‰‡è¢«ä¸‹è½½
            if score == 0:
                # æ£€æŸ¥æ˜¯å¦æ˜¯é«˜è´¨é‡å›¾ç‰‡ï¼ˆå¤§å°ºå¯¸ã€é«˜æ¸…ç­‰ï¼‰
                if any(qual in url_lower for qual in ['large', 'big', 'high', 'hd', '1200', '1920', '800']):
                    score = 1
                elif any(size in url_lower for size in ['thumb', 'small', 'mini', '150', '200']):
                    score = 0.5
                else:
                    score = 1  # ç»™æ‰€æœ‰å›¾ç‰‡ä¸€ä¸ªåŸºç¡€åˆ†æ•°
            
            scored_images.append((url, score))
        
        # æŒ‰åˆ†æ•°æ’åºï¼Œè¿”å›æœ€é«˜åˆ†çš„URL
        if scored_images:
            scored_images.sort(key=lambda x: x[1], reverse=True)
            return scored_images[0][0]
        
        return None
    
    def manual_download_mode(self):
        """æ‰‹åŠ¨ä¸‹è½½æ¨¡å¼ - æ˜¾ç¤ºæ‰€æœ‰æ‰¾åˆ°çš„å›¾ç‰‡ä¾›ç”¨æˆ·é€‰æ‹©"""
        print("ğŸ” æ‰‹åŠ¨ä¸‹è½½æ¨¡å¼ - æ­£åœ¨æ‰«æç½‘ç«™...")
        
        # è·å–æ‰€æœ‰å›¾ç‰‡URL
        main_page_content = self.get_page_content(self.base_url)
        if not main_page_content:
            return
        
        all_image_urls = self.find_images_on_page(main_page_content, self.base_url)
        
        print(f"\nğŸ–¼ï¸  æ‰¾åˆ°ä»¥ä¸‹å›¾ç‰‡ (å…± {len(all_image_urls)} å¼ ):")
        print("=" * 80)
        
        for i, url in enumerate(all_image_urls[:50], 1):  # åªæ˜¾ç¤ºå‰50å¼ 
            filename = os.path.basename(urlparse(url).path)
            print(f"{i:2d}. {filename}")
            print(f"    URL: {url}")
            print()
        
        if len(all_image_urls) > 50:
            print(f"... è¿˜æœ‰ {len(all_image_urls) - 50} å¼ å›¾ç‰‡æœªæ˜¾ç¤º")
    
    def smart_rename_images(self):
        """æ™ºèƒ½é‡å‘½åimagesç›®å½•ä¸‹çš„å›¾ç‰‡æ–‡ä»¶"""
        print("\n" + "=" * 60)
        print("ğŸ¤– å¼€å§‹æ™ºèƒ½é‡å‘½åå›¾ç‰‡æ–‡ä»¶...")
        print("=" * 60)
        
        if not self.images_dir.exists():
            print("âŒ imagesç›®å½•ä¸å­˜åœ¨")
            return
        
        # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        image_files = list(self.images_dir.glob("image_*"))
        if not image_files:
            print("ğŸ“‚ æœªæ‰¾åˆ°éœ€è¦é‡å‘½åçš„å›¾ç‰‡æ–‡ä»¶")
            return
        
        print(f"ğŸ“ å‘ç° {len(image_files)} ä¸ªå›¾ç‰‡æ–‡ä»¶éœ€è¦å¤„ç†")
        
        # å­˜å‚¨é‡å‘½åæ˜ å°„
        rename_mapping = {}
        used_names = set()
        
        # ä¸ºæ¯ä¸ªåˆ†ç±»åˆ›å»ºåŒ¹é…è®¡æ•°å™¨
        category_counters = {}
        for category in self.config['image_categories'].keys():
            category_counters[category] = 1
        
        # éå†æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶è¿›è¡Œæ™ºèƒ½åŒ¹é…
        for image_file in image_files:
            original_name = image_file.name
            file_size = image_file.stat().st_size
            
            print(f"\nğŸ” åˆ†ææ–‡ä»¶: {original_name}")
            print(f"   æ–‡ä»¶å¤§å°: {self.format_file_size(file_size)}")
            
            # æ‰¾åˆ°æœ€ä½³åŒ¹é…çš„é…ç½®é¡¹
            best_match = self.find_best_config_match(original_name, file_size)
            
            if best_match:
                category, config_item, score = best_match
                
                # ç”Ÿæˆæ–°çš„æ–‡ä»¶å
                new_name = self.generate_smart_filename(
                    config_item, category, category_counters, used_names, original_name
                )
                
                if new_name != original_name:
                    rename_mapping[original_name] = new_name
                    used_names.add(new_name)
                    category_counters[category] += 1
                    
                    print(f"   âœ… åŒ¹é…æˆåŠŸ: {config_item['description']}")
                    print(f"   ğŸ“ æ–°æ–‡ä»¶å: {new_name}")
                    print(f"   ğŸ¯ åŒ¹é…åˆ†æ•°: {score}")
                else:
                    print(f"   âœ… æ–‡ä»¶åå·²æ˜¯æœ€ä½³åŒ¹é…")
            else:
                print(f"   âš ï¸  æœªæ‰¾åˆ°åˆé€‚çš„åŒ¹é…ï¼Œä¿æŒåŸæ–‡ä»¶å")
        
        # æ‰§è¡Œé‡å‘½å
        if rename_mapping:
            print(f"\nğŸ“ å‡†å¤‡é‡å‘½å {len(rename_mapping)} ä¸ªæ–‡ä»¶...")
            
            for old_name, new_name in rename_mapping.items():
                old_path = self.images_dir / old_name
                new_path = self.images_dir / new_name
                
                try:
                    old_path.rename(new_path)
                    print(f"   âœ… {old_name} â†’ {new_name}")
                except Exception as e:
                    print(f"   âŒ é‡å‘½åå¤±è´¥ {old_name}: {e}")
            
            print(f"\nğŸ‰ æ™ºèƒ½é‡å‘½åå®Œæˆ! æˆåŠŸé‡å‘½å {len(rename_mapping)} ä¸ªæ–‡ä»¶")
        else:
            print("\nğŸ“‚ æ‰€æœ‰æ–‡ä»¶åéƒ½å·²æ˜¯æœ€ä½³åŒ¹é…ï¼Œæ— éœ€é‡å‘½å")
    
    def find_best_config_match(self, filename, file_size):
        """ä¸ºå›¾ç‰‡æ–‡ä»¶æ‰¾åˆ°æœ€ä½³çš„é…ç½®åŒ¹é…é¡¹"""
        best_score = 0
        best_match = None
        filename_lower = filename.lower()
        
        for category, config_items in self.config['image_categories'].items():
            for config_item in config_items:
                score = 0
                
                # åŸºäºå…³é”®è¯åŒ¹é…
                for keyword in config_item['keywords']:
                    keyword_lower = keyword.lower()
                    if keyword_lower in filename_lower:
                        # å…³é”®è¯åŒ¹é…ç»™åˆ†
                        if len(keyword_lower) > 3:  # é•¿å…³é”®è¯æƒé‡æ›´é«˜
                            score += 15
                        else:
                            score += 8
                
                # åŸºäºæ–‡ä»¶å¤§å°ç‰¹å¾åŒ¹é…
                if file_size > 5 * 1024 * 1024:  # å¤§äº5MBï¼Œå¯èƒ½æ˜¯é«˜è´¨é‡äº§å“å›¾
                    if any(kw in config_item['keywords'] for kw in ['hero', 'main', 'master', 'large']):
                        score += 10
                elif file_size < 50 * 1024:  # å°äº50KBï¼Œå¯èƒ½æ˜¯å›¾æ ‡
                    if any(kw in config_item['keywords'] for kw in ['icon', 'thumb', 'small']):
                        score += 10
                
                # åŸºäºæ–‡ä»¶åæ¨¡å¼åŒ¹é…
                if 'team' in filename_lower and 'team' in ' '.join(config_item['keywords']).lower():
                    score += 20
                if 'footer' in filename_lower and any('icon' in kw for kw in config_item['keywords']):
                    score += 20
                if any(year in filename_lower for year in ['1963']) and '1963' in ' '.join(config_item['keywords']):
                    score += 25
                
                # åŸºäºæ•°å­—IDæ¨¡å¼åˆ¤æ–­ï¼ˆé•¿æ•°å­—IDé€šå¸¸æ˜¯äº§å“å›¾ï¼‰
                long_numbers = re.findall(r'\d{10,}', filename)
                if long_numbers and any(kw in config_item['keywords'] for kw in ['product', 'main', 'detail']):
                    score += 8
                
                if score > best_score:
                    best_score = score
                    best_match = (category, config_item, score)
        
        return best_match if best_score > 5 else None  # æœ€ä½åˆ†æ•°é˜ˆå€¼
    
    def generate_smart_filename(self, config_item, category, counters, used_names, original_name):
        """ç”Ÿæˆæ™ºèƒ½çš„æ–°æ–‡ä»¶å"""
        # è·å–åŸæ–‡ä»¶æ‰©å±•å
        _, ext = os.path.splitext(original_name)
        
        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ–‡ä»¶åä½œä¸ºåŸºç¡€
        base_name = config_item['filename']
        name_without_ext, _ = os.path.splitext(base_name)
        
        # å¦‚æœé…ç½®çš„æ–‡ä»¶åå·²ç»è¢«ä½¿ç”¨ï¼Œæ·»åŠ åºå·
        new_name = base_name
        counter = 1
        
        while new_name in used_names:
            name_parts = name_without_ext.split('_')
            if len(name_parts) > 2:
                # åœ¨æœ€åä¸€ä¸ªéƒ¨åˆ†å‰æ’å…¥åºå·
                name_parts.insert(-1, f"{counter:02d}")
            else:
                name_parts.append(f"{counter:02d}")
            
            new_name = '_'.join(name_parts) + ext
            counter += 1
        
        return new_name
    
    def analyze_image_features(self, image_path):
        """åˆ†æå›¾ç‰‡ç‰¹å¾ï¼ˆæ–‡ä»¶å¤§å°ã€å¯èƒ½çš„å†…å®¹ç±»å‹ç­‰ï¼‰"""
        try:
            file_size = image_path.stat().st_size
            filename = image_path.name.lower()
            
            features = {
                'size': file_size,
                'is_large': file_size > 2 * 1024 * 1024,  # å¤§äº2MB
                'is_small': file_size < 100 * 1024,       # å°äº100KB
                'is_icon': 'icon' in filename or file_size < 10 * 1024,
                'is_banner': 'banner' in filename or file_size > 1024 * 1024,
                'has_numbers': bool(re.search(r'\d{10,}', filename)),
                'has_team': 'team' in filename,
                'has_footer': 'footer' in filename,
            }
            
            return features
        except Exception as e:
            print(f"   âš ï¸  åˆ†æå›¾ç‰‡ç‰¹å¾å¤±è´¥: {e}")
            return {'size': 0}
    
    def analyze_image_with_gemini(self, image_path):
        """ä½¿ç”¨ Gemini Vision API åˆ†æå›¾ç‰‡å†…å®¹ - ä¿æŒåŸå§‹åˆ†è¾¨ç‡"""
        if not self.use_gemini_vision or not self.gemini_model:
            return None
        
        try:
            # æ‰“å¼€å›¾ç‰‡ä½†ä¿æŒåŸå§‹å¤§å°
            image = Image.open(image_path)
            
            print(f"   ğŸ“ åŸå§‹å›¾ç‰‡å°ºå¯¸: {image.width}x{image.height}")
            
            # æ„å»ºåˆ†ææç¤ºè¯
            prompt = """
è¯·åˆ†æè¿™å¼ ç½‘ç«™å›¾ç‰‡ï¼Œå¹¶è¯†åˆ«ä»¥ä¸‹ä¿¡æ¯ï¼š

1. å›¾ç‰‡ç±»å‹ï¼š
   - hero/banner: å¤§å¹…å®£ä¼ å›¾ã€è‹±é›„å›¾ã€æ¨ªå¹…
   - product: äº§å“å›¾ã€å•†å“å›¾
   - detail: ç»†èŠ‚å›¾ã€ç‰¹å†™å›¾
   - icon: å°å›¾æ ‡ã€æŒ‰é’®å›¾æ ‡
   - news: æ–°é—»å›¾ç‰‡ã€æ–‡ç« å›¾ç‰‡
   - team: å›¢é˜Ÿç…§ç‰‡ã€äººç‰©ç…§ç‰‡
   - gallery: ç”»å»Šå›¾ç‰‡ã€å±•ç¤ºå›¾ç‰‡
   - background: èƒŒæ™¯å›¾

2. å†…å®¹ç‰¹å¾ï¼š
   - ä¸»è¦äº§å“æˆ–æœåŠ¡çš„ç‰¹å¾
   - å“ç‰Œå…ƒç´ å’Œè§†è§‰é£æ ¼
   - å›¾ç‰‡çš„ä¸»è¦ç”¨é€”å’ŒåŠŸèƒ½

3. å›¾ç‰‡è´¨é‡å’Œç”¨é€”ï¼š
   - main: é«˜è´¨é‡ä¸»å›¾
   - thumb: ç¼©ç•¥å›¾
   - detail: è¯¦æƒ…å›¾
   - icon: å›¾æ ‡

è¯·ç”¨JSONæ ¼å¼å›å¤ï¼š
{
    "type": "å›¾ç‰‡ç±»å‹",
    "content": "å†…å®¹æè¿°",
    "quality": "å›¾ç‰‡è´¨é‡",
    "description": "ç®€çŸ­æè¿°",
    "confidence": "ç½®ä¿¡åº¦(1-10)"
}"""
            
            print("   ğŸ¤– æ­£åœ¨è°ƒç”¨ Gemini Vision API åˆ†æå›¾ç‰‡...")
            
            # è°ƒç”¨ Gemini Vision API - ä½¿ç”¨åŸå§‹å›¾ç‰‡
            response = self.gemini_model.generate_content([prompt, image])
            
            if response.text:
                print(f"   âœ… AIåˆ†ææˆåŠŸ")
                print(f"   ğŸ“ AIåˆ†æç»“æœ: {response.text[:100]}...")
                return response.text
            else:
                print("   âŒ AIåˆ†ææ— å“åº”")
                return None
                
        except Exception as e:
            error_msg = str(e)
            print(f"   âŒ Gemini åˆ†æå¤±è´¥: {error_msg}")
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºåœ°ç†ä½ç½®é™åˆ¶é”™è¯¯
            if "User location is not supported" in error_msg:
                print("   ğŸš« æ£€æµ‹åˆ°åœ°ç†ä½ç½®é™åˆ¶é”™è¯¯")
                print("   ğŸ’¡ è¯·ä½¿ç”¨VPNè¿æ¥åˆ°æ”¯æŒçš„åœ°åŒºï¼Œæˆ–ä½¿ç”¨åŸºç¡€é‡å‘½åæ¨¡å¼")
                # å¦‚æœåœ¨æ‰¹é‡å¤„ç†ä¸­é‡åˆ°åœ°ç†ä½ç½®é”™è¯¯ï¼Œç›´æ¥é€€å‡º
                if hasattr(self, '_in_batch_processing'):
                    print("\nğŸ›‘ ç”±äºåœ°ç†ä½ç½®é™åˆ¶ï¼Œæ‰¹é‡å¤„ç†å°†ç»ˆæ­¢")
                    sys.exit(1)
            
            return None
    
    def smart_rename_with_gemini(self):
        """ä½¿ç”¨ Gemini Vision API æ™ºèƒ½é‡å‘½åå›¾ç‰‡æ–‡ä»¶ - çº¯AIæ¨¡å¼"""
        print("\n" + "=" * 60)
        print("ğŸ§  ä½¿ç”¨ Gemini Vision AI æ™ºèƒ½é‡å‘½åå›¾ç‰‡æ–‡ä»¶...")
        print("=" * 60)
        
        if not self.use_gemini_vision or not self.gemini_model:
            print("âŒ Gemini Vision API æœªé…ç½®æˆ–ä¸å¯ç”¨")
            print("ğŸ’¡ å»ºè®®: ä½¿ç”¨ './start_download.sh rename' è¿›è¡ŒåŸºç¡€æ™ºèƒ½é‡å‘½å")
            return
        
        # è®¾ç½®æ‰¹é‡å¤„ç†æ ‡å¿—
        self._in_batch_processing = True
        
        if not self.images_dir.exists():
            print("âŒ imagesç›®å½•ä¸å­˜åœ¨")
            return
        
        # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        image_files = []
        for ext in ['jpg', 'jpeg', 'png', 'webp', 'svg']:
            image_files.extend(self.images_dir.glob(f"*.{ext}"))
            image_files.extend(self.images_dir.glob(f"*.{ext.upper()}"))
        
        if not image_files:
            print("ğŸ“‚ æœªæ‰¾åˆ°éœ€è¦é‡å‘½åçš„å›¾ç‰‡æ–‡ä»¶")
            return
        
        print(f"ğŸ“ å‘ç° {len(image_files)} ä¸ªå›¾ç‰‡æ–‡ä»¶éœ€è¦AIåˆ†æ")
        print("âš ï¸  æ³¨æ„: åªä½¿ç”¨Gemini Vision APIï¼Œä¸ä½¿ç”¨é™çº§é€»è¾‘")
        
        # å­˜å‚¨æˆåŠŸåˆ†æçš„ç»“æœ
        successful_analyses = []
        failed_analyses = []
        
        # é€ä¸ªåˆ†æå›¾ç‰‡
        for i, image_path in enumerate(image_files, 1):
            print(f"\nğŸ” [{i}/{len(image_files)}] åˆ†æ: {image_path.name}")
            file_size = image_path.stat().st_size
            print(f"   æ–‡ä»¶å¤§å°: {self.format_file_size(file_size)}")
            
            # ä½¿ç”¨ Gemini Vision åˆ†æ
            gemini_analysis = self.analyze_image_with_gemini(image_path)
            
            if gemini_analysis:
                try:
                    # å°è¯•è§£æJSONå“åº”
                    import json
                    text = gemini_analysis.strip()
                    start = text.find('{')
                    end = text.rfind('}') + 1
                    if start >= 0 and end > start:
                        json_str = text[start:end]
                        analysis_data = json.loads(json_str)
                        
                        print(f"   ğŸ¯ AIè¯†åˆ«ç±»å‹: {analysis_data.get('type', 'æœªçŸ¥')}")
                        print(f"   ğŸ“‹ AIè¯†åˆ«å†…å®¹: {analysis_data.get('content', 'æœªçŸ¥')}")  
                        print(f"   ğŸ† ç½®ä¿¡åº¦: {analysis_data.get('confidence', 0)}/10")
                        
                        # æ ¹æ®AIåˆ†æç”Ÿæˆæ–°æ–‡ä»¶å
                        new_filename = self.generate_ai_filename(image_path, analysis_data)
                        if new_filename and new_filename != image_path.name:
                            successful_analyses.append({
                                'old_path': image_path,
                                'new_filename': new_filename,
                                'analysis': analysis_data
                            })
                            print(f"   âœ… AIæ¨èæ–‡ä»¶å: {new_filename}")
                        else:
                            print(f"   âš ï¸  AIåˆ†æå®Œæˆä½†æ— éœ€é‡å‘½å")
                            failed_analyses.append(image_path.name)
                    else:
                        print(f"   âŒ AIå“åº”æ ¼å¼é”™è¯¯ï¼Œæ— æ³•è§£æJSON")
                        failed_analyses.append(image_path.name)
                        
                except json.JSONDecodeError as e:
                    print(f"   âŒ AIå“åº”JSONè§£æå¤±è´¥: {e}")
                    failed_analyses.append(image_path.name)
            else:
                print(f"   âŒ Gemini Vision AIåˆ†æå¤±è´¥")
                failed_analyses.append(image_path.name)
        
        # æ‰§è¡Œé‡å‘½åæ“ä½œ
        if successful_analyses:
            print(f"\nğŸ“ å‡†å¤‡é‡å‘½å {len(successful_analyses)} ä¸ªAIåˆ†ææˆåŠŸçš„æ–‡ä»¶...")
            renamed_count = 0
            
            for item in successful_analyses:
                old_path = item['old_path']
                new_filename = item['new_filename']
                new_path = old_path.parent / new_filename
                
                try:
                    # é¿å…æ–‡ä»¶åå†²çª
                    if new_path.exists() and new_path != old_path:
                        base, ext = new_filename.rsplit('.', 1)
                        counter = 1
                        while new_path.exists():
                            new_filename = f"{base}_{counter:02d}.{ext}"
                            new_path = old_path.parent / new_filename
                            counter += 1
                    
                    old_path.rename(new_path)
                    print(f"   âœ… {old_path.name} â†’ {new_filename}")
                    renamed_count += 1
                    
                except Exception as e:
                    print(f"   âŒ é‡å‘½åå¤±è´¥ {old_path.name}: {e}")
            
            print(f"\nğŸ‰ Gemini Vision AI æ™ºèƒ½é‡å‘½åå®Œæˆ!")
            print(f"âœ… æˆåŠŸé‡å‘½å: {renamed_count} ä¸ªæ–‡ä»¶") 
            print(f"âŒ åˆ†æå¤±è´¥: {len(failed_analyses)} ä¸ªæ–‡ä»¶")
            
            if failed_analyses:
                print(f"\nâš ï¸  AIåˆ†æå¤±è´¥çš„æ–‡ä»¶:")
                for filename in failed_analyses[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                    print(f"   - {filename}")
                if len(failed_analyses) > 10:
                    print(f"   ... è¿˜æœ‰ {len(failed_analyses) - 10} ä¸ªæ–‡ä»¶")
        else:
            print(f"\nâŒ æ‰€æœ‰æ–‡ä»¶çš„AIåˆ†æéƒ½å¤±è´¥äº†")
            print(f"ğŸ’¡ å»ºè®®æ£€æŸ¥:")
            print(f"   1. Gemini API å¯†é’¥æ˜¯å¦æœ‰æ•ˆ")
            print(f"   2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸") 
            print(f"   3. API é…é¢æ˜¯å¦å……è¶³")
            print(f"   4. åœ°åŒºæ˜¯å¦æ”¯æŒGemini API")
    
    def generate_ai_filename(self, image_path, analysis_data):
        """æ ¹æ®AIåˆ†æç»“æœç”Ÿæˆæ–°æ–‡ä»¶å - æ ¼å¼: å¤§åˆ†ç±»_å°åˆ†ç±»_åç§°_ç³»åˆ—"""
        try:
            image_type = analysis_data.get('type', '').lower()
            content = analysis_data.get('content', '').lower()
            quality = analysis_data.get('quality', '').lower()
            description = analysis_data.get('description', '').lower()
            confidence_raw = analysis_data.get('confidence', 0)
            
            # ç¡®ä¿confidenceæ˜¯æ•°å­—ç±»å‹
            try:
                confidence = float(confidence_raw) if confidence_raw else 0
            except (ValueError, TypeError):
                # å¦‚æœconfidenceæ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œå°è¯•æå–æ•°å­—
                confidence = 0
                if isinstance(confidence_raw, str):
                    import re
                    match = re.search(r'(\d+)', confidence_raw)
                    if match:
                        confidence = float(match.group(1))
            
            # åªå¤„ç†é«˜ç½®ä¿¡åº¦çš„åˆ†æç»“æœ
            if confidence < 5:
                print(f"   âš ï¸  ç½®ä¿¡åº¦è¿‡ä½({confidence}/10)ï¼Œè·³è¿‡é‡å‘½å")
                return None
            
            # è·å–æ–‡ä»¶æ‰©å±•å
            ext = image_path.suffix.lower()
            
            # åˆ†æå¹¶æ˜ å°„åˆ°å¤§åˆ†ç±»
            major_category = self._get_major_category(image_type, content, description)
            
            # åˆ†æå¹¶æ˜ å°„åˆ°å°åˆ†ç±»
            minor_category = self._get_minor_category(image_type, quality, content)
            
            # æå–åç§°
            name = self._extract_name(content, description)
            
            # æå–ç³»åˆ—
            series = self._extract_series(content, description)
            
            # æ„å»ºæ–‡ä»¶å: å¤§åˆ†ç±»_å°åˆ†ç±»_åç§°_ç³»åˆ—
            filename_parts = []
            
            if major_category:
                filename_parts.append(self._sanitize_filename_part(major_category))
            
            if minor_category:
                filename_parts.append(self._sanitize_filename_part(minor_category))
            
            if name:
                filename_parts.append(self._sanitize_filename_part(name))
            
            if series:
                filename_parts.append(self._sanitize_filename_part(series))
            
            # å¦‚æœæ²¡æœ‰è¶³å¤Ÿçš„ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤å€¼
            if len(filename_parts) < 2:
                filename_parts = ['seagull', 'product', 'watch', '01']
            
            # ç”Ÿæˆæœ€ç»ˆæ–‡ä»¶åï¼Œé™åˆ¶é•¿åº¦å¹¶æ¸…ç†ç‰¹æ®Šå­—ç¬¦
            clean_parts = []
            for part in filename_parts[:4]:
                clean_part = self._sanitize_filename_part(part)
                if clean_part and len(clean_part) <= 15:  # é™åˆ¶æ¯éƒ¨åˆ†é•¿åº¦
                    clean_parts.append(clean_part)
            
            if not clean_parts:
                clean_parts = ['seagull', 'product', 'watch', '01']
            
            filename = '_'.join(clean_parts) + ext
            
            return filename
                
        except Exception as e:
            print(f"   âŒ ç”Ÿæˆæ–‡ä»¶åå¤±è´¥: {e}")
            return None
    
    def _clean_field(self, field):
        """æ¸…ç†å­—æ®µï¼Œè½¬æ¢ä¸ºé€‚åˆæ–‡ä»¶åçš„å…¨è‹±æ–‡æ ¼å¼"""
        if not field:
            return ""
        
        # è½¬å°å†™å¹¶ç§»é™¤ç‰¹æ®Šå­—ç¬¦
        clean = str(field).lower().strip()
        
        # ç§»é™¤å¸¸è§æ— ç”¨è¯å’Œç‰¹æ®Šå­—ç¬¦
        clean = clean.replace('/', '_').replace('-', '_').replace(' ', '_')
        clean = clean.replace('ç³»åˆ—', '').replace('series', '')
        
        # å®Œæ•´çš„ä¸­æ–‡åˆ°è‹±æ–‡ç¿»è¯‘æ˜ å°„
        translations = {
            # äº§å“ç³»åˆ—ç›¸å…³
            'é£è¡Œå‘˜è¡¨': 'pilot',
            'é£è¡Œ': 'flight',
            'é™€é£è½®': 'tourbillon',
            'æ½œæ°´è¡¨': 'dive',
            'æ½œæ°´': 'dive', 
            'æµ·æ´‹': 'ocean',
            'å¤å¤': 'retro',
            'ç”µè§†': 'tv',
            'å¥³è¡¨': 'women',
            'å¥³å£«': 'women',
            'ç”·è¡¨': 'men',
            'ç”·å£«': 'men',
            'å¤§å¸ˆ': 'master',
            'å·¥åŒ ': 'craftsman',
            'æœºæ¢°': 'mechanical',
            'è‡ªåŠ¨': 'automatic',
            'çŸ³è‹±': 'quartz',
            
            # å›¾ç‰‡ç±»å‹ç›¸å…³
            'å›¢é˜Ÿ': 'team',
            'æ–°é—»': 'news',
            'èƒŒæ™¯': 'background',
            'ä¸»å›¾': 'main',
            'ç¼©ç•¥å›¾': 'thumb',
            'ç»†èŠ‚': 'detail',
            'äº§å“': 'product',
            'è‹±é›„': 'hero',
            'æ¨ªå¹…': 'banner',
            'å›¾æ ‡': 'icon',
            
            # è´¨é‡å’Œæè¿°ç›¸å…³
            'é«˜æ¸…': 'hd',
            'ç²¾ç¾': 'fine',
            'ä¼˜è´¨': 'quality',
            'ä¸“ä¸š': 'professional',
            'å•†åŠ¡': 'business',
            'è¿åŠ¨': 'sport',
            'ä¼‘é—²': 'casual',
            'æ­£è£…': 'formal',
            'æ—¶å°š': 'fashion',
            'ç»å…¸': 'classic',
            'ç°ä»£': 'modern',
            'ä¼ ç»Ÿ': 'traditional',
            
            # æè´¨ç›¸å…³
            'ç²¾é’¢': 'steel',
            'ä¸é”ˆé’¢': 'steel',
            'é»„é‡‘': 'gold',
            'ç«ç‘°é‡‘': 'rosegold',
            'ç™½é‡‘': 'platinum',
            'é’›åˆé‡‘': 'titanium',
            'é™¶ç“·': 'ceramic',
            'çš®é©': 'leather',
            'æ©¡èƒ¶': 'rubber',
            
            # å¸¸è§è¯æ±‡æ¸…ç†
            'æ‰‹è¡¨': 'watch',
            'è…•è¡¨': 'watch',
            'æ—¶è®¡': 'timepiece',
            'è¡¨': '',  # å•ç‹¬çš„"è¡¨"å­—ç§»é™¤
            'æ¬¾': '',  # "æ¬¾"å­—ç§»é™¤
            'å‹': '',  # "å‹"å­—ç§»é™¤
            'çº§': '',  # "çº§"å­—ç§»é™¤
        }
        
        # æ‰§è¡Œç¿»è¯‘
        for chinese, english in translations.items():
            clean = clean.replace(chinese, english)
        
        # ç§»é™¤å¤šä½™çš„ä¸‹åˆ’çº¿å’Œç©ºå€¼
        clean = re.sub(r'_+', '_', clean).strip('_')
        
        # ç§»é™¤ä»»ä½•å‰©ä½™çš„ä¸­æ–‡å­—ç¬¦
        clean = re.sub(r'[\u4e00-\u9fff]+', '', clean)
        
        # æœ€ç»ˆæ¸…ç†
        clean = re.sub(r'_+', '_', clean).strip('_')
        
        return clean
    
    def _extract_description_keyword(self, description):
        """ä»æè¿°ä¸­æå–ä¸€ä¸ªæ€»ç»“æ€§çš„è‹±æ–‡å…³é”®è¯"""
        if not description:
            return ""
        
        # ä¸­æ–‡åˆ°è‹±æ–‡çš„ç¿»è¯‘æ˜ å°„
        chinese_translations = {
            'æ‰‹è¡¨': 'watch',
            'è…•è¡¨': 'watch', 
            'æ—¶è®¡': 'timepiece',
            'æœºèŠ¯': 'movement',
            'è¡¨ç›˜': 'dial',
            'è¡¨å¸¦': 'strap',
            'è¡¨é“¾': 'bracelet',
            'è¡¨å† ': 'crown',
            'æŒ‡é’ˆ': 'hands',
            'åˆ»åº¦': 'marker',
            'å¤œå…‰': 'luminous',
            'é˜²æ°´': 'waterproof',
            'è®¡æ—¶': 'chrono',
            'æ—¥å†': 'calendar',
            'æœˆç›¸': 'moonphase',
            'åŠ¨åŠ›': 'power',
            'å‚¨èƒ½': 'reserve',
            'ç²¾é’¢': 'steel',
            'é»„é‡‘': 'gold',
            'ç«ç‘°é‡‘': 'rosegold',
            'é’›åˆé‡‘': 'titanium',
            'é™¶ç“·': 'ceramic',
            'è“å®çŸ³': 'sapphire',
            'çš®é©': 'leather',
            'æ©¡èƒ¶': 'rubber',
            'å°¼é¾™': 'nylon',
            'ç”·å£«': 'men',
            'å¥³å£«': 'women',
            'è¿åŠ¨': 'sport',
            'å•†åŠ¡': 'business',
            'ä¼‘é—²': 'casual',
            'æ­£è£…': 'formal',
            'å¤å¤': 'vintage',
            'ç°ä»£': 'modern',
            'ç»å…¸': 'classic',
            'æ—¶å°š': 'fashion',
            'ä¼˜é›…': 'elegant',
            'ç²¾è‡´': 'refined',
            'è±ªå': 'luxury',
            'é™é‡': 'limited',
            'ç‰¹åˆ«': 'special',
            'çºªå¿µ': 'commemorative'
        }
        
        # ä¼˜å…ˆçº§å…³é”®è¯æ˜ å°„ï¼ˆæŒ‰é‡è¦æ€§æ’åºï¼‰
        priority_keywords = {
            # é«˜ä¼˜å…ˆçº§ - äº§å“ç‰¹å¾
            'tourbillon': 'tourbillon',
            'skeleton': 'skeleton', 
            'chronograph': 'chrono',
            'diving': 'dive',
            'pilot': 'pilot',
            'aviation': 'aviation',
            'military': 'military',
            'dress': 'dress',
            'sport': 'sport',
            
            # ä¸­ä¼˜å…ˆçº§ - æè´¨å’ŒåŠŸèƒ½
            'gold': 'gold',
            'steel': 'steel',
            'titanium': 'titanium',
            'ceramic': 'ceramic',
            'automatic': 'auto',
            'mechanical': 'mech',
            'quartz': 'quartz',
            'solar': 'solar',
            
            # ä½ä¼˜å…ˆçº§ - é¢œè‰²å’ŒåŸºæœ¬æè¿°
            'black': 'black',
            'white': 'white', 
            'blue': 'blue',
            'brown': 'brown',
            'silver': 'silver',
            'rose': 'rose'
        }
        
        desc_lower = description.lower()
        
        # é¦–å…ˆç¿»è¯‘ä¸­æ–‡
        for chinese, english in chinese_translations.items():
            if chinese in desc_lower:
                desc_lower = desc_lower.replace(chinese, english)
        
        # æŒ‰ä¼˜å…ˆçº§æŸ¥æ‰¾å…³é”®è¯
        for keyword, short in priority_keywords.items():
            if keyword in desc_lower:
                return short
        
        # å¦‚æœæ²¡æ‰¾åˆ°ä¼˜å…ˆå…³é”®è¯ï¼ŒæŸ¥æ‰¾ç¬¬ä¸€ä¸ªæœ‰æ„ä¹‰çš„è‹±æ–‡å•è¯
        words = re.findall(r'\b[a-zA-Z]{4,}\b', desc_lower)
        if words:
            # è¿‡æ»¤æ‰å¸¸è§æ— æ„ä¹‰è¯æ±‡
            filtered_words = [w for w in words if w not in [
                'this', 'that', 'with', 'from', 'have', 'been', 'they', 'were',
                'said', 'each', 'which', 'their', 'time', 'will', 'about', 'image',
                'picture', 'photo', 'showing', 'display', 'featuring', 'contains'
            ]]
            if filtered_words:
                return filtered_words[0].lower()
        
        # æœ€åå°è¯•æå–3å­—æ¯å•è¯
        words_3 = re.findall(r'\b[a-zA-Z]{3}\b', desc_lower)
        useful_3_words = [w for w in words_3 if w not in ['the', 'and', 'for', 'are', 'you', 'all', 'any', 'can', 'had', 'her', 'was', 'one', 'our', 'out', 'day', 'get', 'has', 'him', 'his', 'how', 'its', 'may', 'new', 'now', 'old', 'see', 'two', 'way', 'who', 'boy', 'did', 'end', 'few', 'man', 'men', 'put', 'say', 'she', 'too', 'use']]
        if useful_3_words:
            return useful_3_words[0].lower()
        
        return ""
    
    def _clean_series_name(self, series):
        """æ¸…ç†ç³»åˆ—åç§°ï¼Œç”Ÿæˆé€‚åˆæ–‡ä»¶åçš„æ ¼å¼"""
        if not series:
            return ""
        
        # ç§»é™¤å¸¸è§çš„åç¼€
        clean = series.replace('ç³»åˆ—', '').replace('series', '').strip()
        
        # æ›¿æ¢ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦
        clean = clean.replace(' ', '_').replace('/', '_').replace('-', '_')
        
        # ç§»é™¤å¤šä½™çš„ä¸‹åˆ’çº¿
        clean = re.sub(r'_+', '_', clean).strip('_')
        
        # ç¿»è¯‘å¸¸è§çš„ä¸­æ–‡ç³»åˆ—å
        translations = {
            'é£è¡Œ': 'flight',
            'é™€é£è½®': 'tourbillon', 
            'æ½œæ°´': 'dive',
            'æµ·æ´‹': 'ocean',
            'å¤å¤': 'retro',
            'ç”µè§†': 'tv',
            'å¥³è¡¨': 'women',
            'å¤§å¸ˆ': 'master',
            'å·¥åŒ ': 'craftsman'
        }
        
        for chinese, english in translations.items():
            clean = clean.replace(chinese, english)
        
        return clean.lower()
    
    def _get_major_category(self, image_type, content, description):
        """è·å–å¤§åˆ†ç±»"""
        text = f"{image_type} {content} {description}".lower()
        
        # å®šä¹‰å¤§åˆ†ç±»æ˜ å°„
        if any(word in text for word in ['hero', 'banner', 'main', 'header']):
            return 'seagull'
        elif any(word in text for word in ['product', 'watch', 'timepiece', 'tourbillon', 'pilot', 'dive']):
            return 'seagull'
        elif any(word in text for word in ['team', 'people', 'person', 'staff']):
            return 'seagull'
        elif any(word in text for word in ['news', 'article', 'story']):
            return 'seagull'
        elif any(word in text for word in ['icon', 'button', 'social']):
            return 'seagull'
        else:
            return 'seagull'
    
    def _get_minor_category(self, image_type, quality, content):
        """è·å–å°åˆ†ç±»"""
        text = f"{image_type} {quality} {content}".lower()
        
        # å®šä¹‰å°åˆ†ç±»æ˜ å°„
        if any(word in text for word in ['hero', 'banner', 'main']):
            return 'hero'
        elif any(word in text for word in ['product', 'watch', 'timepiece']):
            return 'product'
        elif any(word in text for word in ['detail', 'close', 'zoom']):
            return 'detail'
        elif any(word in text for word in ['team', 'people', 'person']):
            return 'team'
        elif any(word in text for word in ['news', 'article']):
            return 'news'
        elif any(word in text for word in ['icon', 'button']):
            return 'icon'
        elif any(word in text for word in ['gallery', 'collection']):
            return 'gallery'
        elif any(word in text for word in ['background', 'bg']):
            return 'background'
        else:
            return 'product'
    
    def _extract_name(self, content, description):
        """æå–åç§°"""
        text = f"{content} {description}".lower()
        
        # å®šä¹‰åç§°æ˜ å°„
        if any(word in text for word in ['tourbillon', 'é™€é£è½®']):
            return 'tourbillon'
        elif any(word in text for word in ['pilot', 'é£è¡Œ', 'aviation', '1963']):
            return '1963pilot'
        elif any(word in text for word in ['dive', 'æ½œæ°´', 'ocean']):
            return 'dive'
        elif any(word in text for word in ['retro', 'å¤å¤', 'tv', 'ç”µè§†']):
            return 'retrotv'
        elif any(word in text for word in ['women', 'å¥³', 'lady']):
            return 'women'
        elif any(word in text for word in ['skeleton', 'é•‚ç©º']):
            return 'skeleton'
        elif any(word in text for word in ['team', 'å›¢é˜Ÿ']):
            return 'team'
        elif any(word in text for word in ['main', 'hero', 'banner']):
            return 'main'
        else:
            return 'main'
    
    def _extract_series(self, content, description):
        """æå–ç³»åˆ—"""
        text = f"{content} {description}".lower()
        
        # å®šä¹‰ç³»åˆ—æ˜ å°„
        if any(word in text for word in ['gold', 'é‡‘', 'golden']):
            return 'gold'
        elif any(word in text for word in ['skeleton', 'é•‚ç©º', 'open']):
            return 'skeleton'
        elif any(word in text for word in ['steel', 'é’¢', 'stainless']):
            return 'steel'
        elif any(word in text for word in ['jewel', 'å®çŸ³', 'diamond']):
            return 'jewels'
        elif any(word in text for word in ['glitch', 'æ•…éšœ', 'effect']):
            return 'glitch'
        elif any(word in text for word in ['thumb', 'small', 'ç¼©ç•¥']):
            return 'thumb'
        elif any(word in text for word in ['01', '02', '03', '04', '05']):
            # æå–æ•°å­—ç³»åˆ—
            import re
            numbers = re.findall(r'\d{2}', text)
            if numbers:
                return numbers[0]
            return '01'
        else:
            return '01'
    
    def _sanitize_filename_part(self, part):
        """æ¸…ç†æ–‡ä»¶åç»„ä»¶ï¼Œç¡®ä¿å®‰å…¨ä¸”ç®€æ´"""
        if not part:
            return ""
        
        # è½¬æ¢ä¸ºå­—ç¬¦ä¸²å¹¶è½¬å°å†™
        clean = str(part).lower().strip()
        
        # ç§»é™¤æ‰€æœ‰éè‹±æ–‡å­—æ¯æ•°å­—å­—ç¬¦ï¼Œåªä¿ç•™å­—æ¯æ•°å­—å’Œè¿å­—ç¬¦
        import re
        clean = re.sub(r'[^a-z0-9\-]', '', clean)
        
        # ç§»é™¤å¤šä½™çš„è¿å­—ç¬¦
        clean = re.sub(r'-+', '-', clean).strip('-')
        
        # é™åˆ¶é•¿åº¦
        if len(clean) > 15:
            clean = clean[:15]
        
        return clean


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ–¼ï¸ Image-tools é€šç”¨å›¾ç‰‡ä¸‹è½½å™¨")
    print("=" * 60)
    
    downloader = ImageDownloader()
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        if sys.argv[1] == '--manual':
            downloader.manual_download_mode()
        elif sys.argv[1] == '--match':
            # å¼ºåˆ¶ä½¿ç”¨åŒ¹é…æ¨¡å¼
            downloader.force_matching_mode = True
            downloader.search_and_download_images()
        elif sys.argv[1] == '--all':
            # å¼ºåˆ¶ä½¿ç”¨å…¨é‡ä¸‹è½½æ¨¡å¼
            downloader.force_download_all = True
            downloader.search_and_download_images()
        elif sys.argv[1] == '--rename':
            # åªæ‰§è¡Œæ™ºèƒ½é‡å‘½å
            downloader.smart_rename_images()
        elif sys.argv[1] == '--gemini':
            # ä½¿ç”¨ Gemini Vision æ™ºèƒ½é‡å‘½å
            downloader.smart_rename_with_gemini()
        else:
            print("âŒ æœªçŸ¥å‚æ•°ã€‚å¯ç”¨å‚æ•°:")
            print("   --manual : æ‰‹åŠ¨æ¨¡å¼ï¼Œæ˜¾ç¤ºæ‰€æœ‰å›¾ç‰‡ä¾›é€‰æ‹©")
            print("   --match  : æ™ºèƒ½åŒ¹é…æ¨¡å¼")
            print("   --all    : å…¨é‡ä¸‹è½½æ¨¡å¼")
            print("   --rename : æ™ºèƒ½é‡å‘½åæ¨¡å¼")
            print("   --gemini : Gemini Vision æ™ºèƒ½é‡å‘½åæ¨¡å¼")
    else:
        # é»˜è®¤ä½¿ç”¨å…¨é‡ä¸‹è½½æ¨¡å¼
        downloader.force_download_all = True
        downloader.search_and_download_images()


if __name__ == '__main__':
    main() 